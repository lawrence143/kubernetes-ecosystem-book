
<b> Microservices, Containers, Kubernetes and Multi-Cloud</b> 

Having understood the strategically sound advantages of the fast-emerging and evolving multi-cloud paradigm, worldwide enterprises are increasingly embracing the multi-cloud strategy for their business automation and acceleration. However, there are a few key constraints as far as employing multiple cloud environments for hosting and managing enterprise, cloud, web, mobile, and embedded applications. There are a few noteworthy innovations, disruptions and transformations in the cloud space. There is a bevy of automated tools being produced and released in order to simplify and streamline the multi-cloud adoption. Interestingly, with the emergence of microservices architecture (MSA), Docker-enabled containerization, and container orchestration platforms such as Kubernetes, the multi-cloud adoption gets speeded up remarkably across industries. 

Microservices architecture (MSA) is being positioned as the most optimal architectural pattern for designing, developing and deploying cloud applications. With the Docker platform capturing a lot of market and mind shares, the containerization movement has steadily taken off with much fanfare. Containers are the best fit for hosting and running microservices and their instances. The cool convergence of containers and microservices opens up fresh possibilities and opportunities. Kubernetes is strengthening its lead over other container clustering, orchestration and management platforms. Thus, the versatile combination of microservices, containers and Kubernetes is going to be a distinct game-changer for the future of software engineering. This book is all about the erudition of Kubernetes and its army of tools towards for deploying Kubernetes-managed, containerized and microservices-centric applications in multi-cloud environments.
Entering into the Digital Era
The faster maturity and stability of digital technologies (Cloud computing, data analytics, the Internet of things (ioT), artificial intelligence (AI), microservices, mobility, edge computing, cyber security, etc.,) is all set to usher the promised digital era. 

•	Firstly, the next-generation Internet (that is, the IoT) is to lead to the realization of trillions of digitized elements/smart objects/sentient materials. Today our compute servers, desktops and laptops are integrated with one another through the Internet. Our mobile phones and phablets are being hooked to the Internet. The forthcoming Internet will encompass not only computers and communicators but also all kinds of physical, mechanical, electrical and electronics devices. That is, all kinds of common and casual objects in our everyday environments are all set to be digitized elements, which are destined to become computational, communicative, sensitive, perceptive, decision-making, and active. There are a number of promising and potential digitization and edge technologies (sensors, actuators, chips, codes, controllers, beacons, LEDs, stickers, tags, etc.) for meticulously transitioning ordinary elements into extraordinary artifacts in our personal and professional environments. Digitized elements are innately capable of joining in the mainstream computing to succulently enable situation and surroundings-awareness.  

•	Secondly, there are many lightweight communication and data transmission protocols enabling extreme connectivity and integration among our everyday devices, machines, instruments, equipment, appliances, drones, robots, consumer electronics, etc. That is, we are going to be bombarded with a large number of handy and trendy, slim and sleek, resource-constrained as well as intensive, embedded and networked systems.  It is forecast that there will be billions of connected devices in the years ahead. 

•	Finally, with the widespread and smart utilization of the microservices architecture philosophies, it is anticipated that there will be millions of software services (business applications, IT services, device services, etc.). The supporting platforms (design, development, debugging, delivery, deployment, and decommission), databases, middleware, and  other platform solutions for monitoring, measurement, management, governance, orchestration, brokerage, security, compliance, etc. of business workloads and IT services are steadily modernized and migrated to cloud environments. With the surging popularity of edge or fog analytics solutions and with the accelerated formation of edge device clouds, real-time data capture, storage, processing, decision-making, and action are bound to see the light. 

When these three categories of enabled systems (digitized objects, connected devices and software services) interact with one another in a purpose-driven manner, there will be a staggering amount of multi-structured data (alternatively termed as big data) getting generated. The challenge here is how to collect, cleanse, crunch the big data quickly to discover and disseminate knowledge. However, with the availability of integrated data analytics platforms,  a litany of pioneering machine and deep learning algorithms, and other knowledge discovery methods, data sets are subjected to a variety of investigations and this highly complicated process can lead to actionable insights, which can be looped back to devices, systems, and applications to exhibit a kind of adaptivity, agility, autonomy and adroitness in their operations, offerings and outputs. 

Software-defined Cloud Environments for the Digital Era

The arrival of cloud concepts has brought in remarkable changes in the IT deployment model that in turn has led in realizing big transitions in the delivery of business applications and services. The cloud paradigm results in the sagacious enhancement of business flexibility, productivity, and sustainability. Formally cloud infrastructures are consolidated, centralized, containerized, virtualized, automated, and shared IT infrastructures. The utilization rate of cloud IT infrastructures is going up steadily. Still, there are dependencies curtailing the full usage of expensive IT resources. The ways and means for realizing the enhanced usage include employing the decoupling technique among various IT assets. This decoupling ultimately assists for decimating all kinds of constricting dependencies. Further on, attaining more intensive and insightful process excellence through optimization, integration, orchestration and policy-based configuration, operation, management, delivery, and maintenance is being insisted. By attaching external knowledge bases is another option to make IT resources adaptive, agile and affordable. Precisely speaking all kinds of IT operations have to be algorithmically automated. IT infrastructure provisioning, application configuration and deployment, IT service management, cyber security, etc. are being automated through a variety of path-breaking technologies and tools. Thus, a stream of pioneering software solutions is being brought in to realize programmable IT infrastructures.  

The software-defined infrastructures (SDI) paradigm is the future for IT to set up and sustain application-aware, nimble, lean, and green IT infrastructures.  The leverage of commodity servers and the compartmentalization (virtualization and containerization) aspect is being touted as the way forward towards SDI. Let us begin with the commoditization technique. 

•	Software-defined Compute Machines – The goal is to realize programmable compute servers. The tried and time-tested abstraction aspect is being recommended for fulfilling this need. The virtualization and containerization paradigms facilitate any physical machine (PM) (alternatively referred to as bare metal (BM) servers) to be expressed and exposed as a collection of virtual machines and containers. This sort of partitioning /programming of physical machines sharply increases their utilization level. Not only high-end servers but also low-end server machines can be segmented like this. Resultantly, servers are virtualized, containerized, manipulated, configured, customized and shared across many clients, publicly discovered and leveraged over any network. The computing capability gets delivered as a service on demand, billed for the usage only, automatically provisioned, composed towards large-scale clusters, monitored, measured, and managed through automated tools. Compute servers are performance-tuned, made policy-aware, automatically scaled up and out based on brewing user, data and processing loads and needs, etc. In short, cloud servers are being made workloads-aware. 

•	Software-defined Networking - On the networking front, the propriety and expensive network switches and routers and other networking solutions/appliances in any IT data centers and server farms are consciously commoditized through a kind of logical separation. That is, the control plane (with embedded intelligence) gets abstracted out and hence, the routers and switches have only the data forwarding plane.  That means, there is less intelligence into these routers and switches thereby the goal of commoditization of network elements is technologically enabled. The controlling intelligence embedded inside various networking solutions are adroitly segregated and is being separately developed and presented as a software controller. This transition makes routers and switches dumb as they lose out their costly intelligence. Also, this strategically sound segregation comes handy in interchanging one router /switch with another one from a different manufacturer. The vendor lock-in problem simply vanishes with the application of the widely dissected and deliberated abstraction concept. Now with the controlling stake is in pure software form, incorporating any kind of patching in addition to configuration and policy changes in the controlling module can be done quickly in a risk-free and rapid manner. With such a neat and nice abstraction procedure, routers and switches are becoming commoditized entities. There is a number of fresh business and technical advantages as the inflexible networking in present-day IT environments is steadily inching towards to gain the venerable and wholesome benefits of the commoditized networking.   

•	The Commoditization of Storage Appliances – Similar to the commoditization of networking components, all kinds of storage solutions are being commoditized by adding an abstraction layer above the storage appliances and arrays. 
Software-defined cloud infrastructures are programmable, highly utilizable, sustainable, and affordable. Cloud environments (public and private) are increasingly software-defined. Formation of hybrid clouds is getting simplified through a host of advancements in the cloud space. Cloud-to-cloud (C2C) integration is picking up fast through automated solutions. That is, geographically distributed cloud environments are being integrated in an ad hoc manner in on-demand manner based on the varying demands. 

Demystifying the Hybrid IT Era

Hybrid cloud is an on-demand combination of on-premises (private cloud) and public cloud services to bring forth an exemplary value for businesses. The hybrid IT is the most influential and important moment for worldwide businesses in order to guarantee enhanced value for their customers, consumers, partners, employees, etc. The hybrid environment provides customers with all the flexibility and extensibility to select and consume the most appropriate service offering for specific workloads based on several critical factors such as cost, security, network latency, controllability, visibility and performance. For example, a customer may choose a public cloud service to test and develop a new application and then move that workload to a private cloud or traditional IT environment when the application becomes operational. Enterprises that need to support a variety of workloads can leverage the flexibility of a hybrid cloud approach to ensure they have the ability to scale up and scale down as needed. The emerging hybrid capability through a bevy of automated tools is a blessing in disguise for worldwide enterprises to meet up the fast-evolving business sentiments.
The Key Drivers for Hybrid Clouds
Hybrid cloud is a kind of converged cloud computing environment which uses a mix of on-premise private cloud and public cloud services with seamless interaction between the participating platforms. While some of the organizations are looking to put selective IT functions onto a public cloud, they still prefer keeping the higher-risk or more bespoke functions in a private/on-premise environment. Sometimes the best infrastructure for an application requires both cloud and dedicated environments. That is being touted as the prime reason for having hybrid clouds (as illustrated in figure 1). 

•	Public cloud for cost-effective scalability and ideal for heavy or unpredictable traffic
•	Private cloud for complete control and security aspects
•	Dedicated servers for super-fast performance and reliability

 

Figure 1 – The Formation of Hybrid Cloud

A hybrid cloud typically offers the following features:

•	Flexibility - The availability of both scalable, cost-effective public resource and secure resource can provide better opportunities for organizations to explore different operational avenues
•	Cost efficiency - Public clouds are likely to offer significant economies of scale (such as centralized management) and greater cost efficiencies than the private cloud. Hybrid cloud model, therefore, allows organizations to unlock these savings for as many business functions as possible and still keeping sensitive operations secure
•	Security - The private cloud feature in the hybrid cloud model not only provides the security where it is required for sensitive operations but can also meet regulatory requirements for data handling & storage where it is applicable
•	Scalability - Although private clouds offer a certain level of scalability based on the configurations (whether they are hosted externally or internally), public cloud services do offer scalability with fewer boundaries as resources are pulled from the larger cloud infra. By moving as many non-sensitive functions as possible to the public cloud infrastructure, this would allow organizations to benefit from public cloud scalability even as reducing the demands on a private cloud.

Hybrid clouds succulently empower enterprises to innovate rapidly while fulfilling the enterprise-grade performance, resiliency and security requirements. 

The Hybrid Cloud Benefits

Hybrid cloud ensures the widely articulated enterprise IT needs by immaculately combining the control and reliability of private cloud with the scalability, consumability, observability, and cost-efficiency of public clouds. Leveraging hybrid cloud environments enables you to run every workload in its appropriate place at optimal cost. 

Integration of applications, data, and services - A hybrid cloud creates the transparency needed to see and connect data and applications across infrastructures. For example, a hybrid cloud approach can foster integration between internal systems of record, often housed on traditional IT or on a private cloud, and more outward-facing systems of engagement, which are increasingly hosted on a public cloud.

Composition and management of business workloads - An agile and competitive business is increasingly a composable business. In any composable business, all sorts of processes, applications, services, and data become building blocks. These blocks are quickly and easily found, bound and assembled and re-assembled in the cloud to find new ways to rapidly innovate and engage with customers. Distributed and different cloud environments combine well to realize composable businesses. A hybrid cloud enhances developer productivity so applications can be integrated, composed, and delivered.

Portability of data and applications - In a hybrid environment, developers can rapidly connect and compose data and services for the enterprise, the web, and mobile applications, allowing organizations to act fast. Perhaps we need to make an application available in a new country or move from a development and test environment to production or move from primary capacity to scale-out capacity

Flexibility with Speed – Hybrid clouds offer the broadest choice of platforms and infrastructures on which to build and deploy a range of applications at the speed required for business needs

Value-driven with Variety – Ubiquitous access to data sources for applications, a growing software market store, and integrated platforms across on-premise and off-premise clouds 

Reliability with Resiliency – Unbreakable and impenetrable data security along with application resiliency is the distinct hallmarks of hybrid clouds

Cost Optimization – The choice of cloud environments for efficiently and affordably running application workloads is being facilitated through hybrid clouds. 

Enhanced Utilization – By leveraging the already invested and installed IT infrastructures, the IT costs could be kept low. Underutilized and unutilized infrastructural resources can be used to the highest value. 

The Hybrid Cloud Use Cases 

It is possible to achieve higher levels of control, reliability, availability, elasticity, quality and performance in hybrid cloud environments. Customers have acknowledged the following five key use cases for a hybrid cloud implementation. 

Development and Testing - Hybrid cloud provides businesses with the required flexibility to gain the needed capacity for limited time periods without making capital investments for additional IT infrastructures. 

Extending Existing Applications - With a hybrid cloud, businesses can extend current standard applications to the cloud to meet the needs of rapid growth or free up onsite resources for more business-critical projects. 

Disaster Recovery - Every organization fears an outage, or outright loss, of business-critical information. While onsite disaster recovery solutions can be expensive, preventing businesses from adopting the protection plans they need, a hybrid cloud can offer an affordable disaster recovery solution with flexible commitments, capacity, and cost. 

Web and Mobile Applications - Hybrid cloud is ideal for cloud-native and mobile applications that are data-intensive and tend to need the elasticity to scale with sudden or unpredictable traffic spikes. With a hybrid cloud, organizations can keep sensitive data onsite and maintain existing IT policies to meet the application’s security and compliance requirements. 

Development Operations - As developers and operations teams work closely together to increase the rate of delivery and quality of deployed software, a hybrid cloud allows them to not only blur the lines between the roles, but between Dev/Test and production, and between onsite and offsite placement of workloads.

Capacity Expansion - Quickly address resource constraints by bursting workloads any cloud environments.

Data Center Consolidation - Consolidate legacy infrastructures onto an automated and centrally managed software-defined data center.

The adoption of hybrid clouds is being driven due to several parameters as articulated above. The mandate towards highly optimized and organization cloud environments for enabling smarter organizations is the key force for hybrid clouds. The heightened stability and surging popularity of hybrid clouds ultimately lead to multi-cloud environments.

Eventually hybrid clouds get extended to accommodate different public clouds resulting in the realization of the multi-cloud concept. 

The future noticeably beckons and reckons for hybrid clouds. The cloud journey thus far is simply a roller coaster ride. Clouds are typically online, on-demand, and off-premise / on-premise. There are public, private, and hybrid clouds to comfortably cater to different regions and requirements. There is a number of purpose-specific cloud environments to suit different communities. Precisely speaking, there are environment-specific, organization-wide, business-centric, remote, and localized clouds comprising a growing array of compute resources such as bare metal servers, virtual machines and containers. The other prominent resources include storage, networking and security solutions. The faster stability and stability of cloud platforms have made it easy to bring forth competent cloud environments quickly. 

In the recent past, there are edge / fog device clouds emerging and evolving fast with the conscious adoption of edge / fog computing paradigms. That is, multi-faceted devices are being meticulously clubbed together to form powerful and pioneering device clouds to attend environment-specific and time-sensitive tasks. On the other hand, there are massive public clouds by various providers to meet their clients’ computing, networking and storage needs. Thus the cloud evolution and revolution are definitely and decisively amazing. The next innovation, disruption and transformation in this mesmerizing journey is to form and leverage hybrid clouds comprising edge, private and public clouds. Many kinds of distributed cloud environments are to be connected with one another to achieve bigger and better things for the IT, which is invariably mandated to do more with less. However, the formation and sustenance of hybrid clouds is beset with a number of business, technical and user challenges and concerns. 

Demystifying Microservices Architecture (MSA)

Lately, microservices architecture is gaining a lot of mind and market shares. Monolithic and massive applications are being continuously dismantled to be a pool of easily manageable and composable microservices. Application development and maintenance (ADM) service providers know the perpetual difficulties of  building and sustain legacy applications, which are closed, inflexible, and expensive. The low utilization and reuse are other drawbacks. Enabling them to be web, mobile and cloud-ready is beset with a number of practical challenges. Modernizing and migrating legacy applications to embrace newer technologies and to run them in optimized IT environments consume a lot of time, talent and treasure. Software development takes the agile route to bring forth business value in the shortest possible time. Software delivery and deployment are getting equally speeded up through the DevOps concept, which is being facilitated through a host of powerful automation tools and techniques. Now the software solution design also has to be accelerated in a risk-free fashion. Here comes the microservices architecture style and pattern. 

Microservices is emerging as an excellent architecture style enabling the division of large and complex applications into micro-scale yet many services, each runs in its own process, has its own APIs, and communicates with one another using lightweight mechanisms such as HTTP. Microservices are built around business capabilities, loosely coupled and highly cohesive, horizontally scalable, independently deployable, technology-agnostic, etc. Each microservice is supposed to do one task well. On the other side, when these microservices get systematically composed, the realization of enterprise-scale, and business-critical applications. in which large complex software applications are composed out of several services. It is quite easy to deploy newer versions of microservices frequently. That is, any kind of user recommendations, business sentiment changes and technology updates can be deftly accommodated and delivered. Similarly designing, developing, debugging, delivering, deploying and decommissioning newer microservices can be swiftly done.  There are enabling platforms and optimized IT infrastructures for the faster realization of microservices, which can be easily and quickly deployed. 

Microservices are also innately facilitating horizontal scalability. Microservices are self-defined, autonomous and decoupled. The dependency-imposed constrictions are elegantly eliminated thereby faults are tolerated and the required isolation is being achieved. Microservices development teams can independently deliver on business requirements faster. However, there are some fresh operational challenges being associated with microservices-centric applications. Microservices ought to be dynamically discovered. On finding the network location addresses, the control and data flows have to be precisely routed to the correct and functioning microservices. There has to be a controlled and secured access to microservices, which need to be minutely monitored, measured and managed in order to fulfil the designated business targets can be attained. All kinds of logging and operational data have to be consciously and consistently collected, cleansed and crunched in order to extricate usable and useful operational insights in time. Microservices are increasingly containerized and powerful DevOps tools (continuous building, integration, testing, delivery and deployment) are being used for business-empowerment. 

In spite of all those top claims, microservices architecture is simplistically an evolutionary one. It inherits some of the baggage of the previous incarnation, which is nonetheless the service oriented architecture (SOA) pattern. Enterprise service bus (ESB) is the service bus/gateway/broker/messaging middleware in the SOA world. ESB comes with service discovery, mediation, enrichment, resiliency, security and other concierge-like capabilities. However, in the ensuing microservices era, the ESB-like monolithic software gets expressed and exposed as a dynamic set of interactive microservices. The beauty lies in segregating business capabilities from all kinds of support services. As illustrated below, the networking/communication functionalities are separated out of the core activities of microservices. This segregation brings forth a number of business and technical advantages. 
 
. 

Delineating the Containerization Paradigm

Containers emerge as the efficient runtime and resource for cloud applications (both cloud-enabled and native). Containers are comparatively lightweight and hence hundreds of containers can be made to run in a physical or virtual machine. There are other technical benefits such as horizontal scalability, portability, etc. Containers almost guarantee the performance of physical machines. Near-time scalability is seeing the reality with the faster maturity and stability of the enigmatic containerization paradigm. The tool ecosystem of containerization movement is growing rapidly and hence containers are being positioned as the perfect way forward to attain the originally envisaged benefits of cloudification. 

Containers are being positioned as the most appropriate resource and runtime to host and execute scores of microservices and their instances. The container monitoring, measurement and management requirements are being speeded up with the availability of several open source as well as commercial-grade monitoring and data analytics solutions. The container networking and storage aspects are seeing a lot of tractions these days. Precisely speaking, there are a number of automated tools and viable approaches towards making containerization penetrative, participative and pervasive. 

	Why Containerization is pampered? - The old way to deploy applications was to install software applications on a bare metal server/physical machine (node/host) using the operating system (OS) package manager. This had led to the disadvantage of entangling the applications’ executables, configuration, libraries, and other dependencies with each other and with the underlying host OS. With the faster maturity and stabilization of virtualization, the overwhelming practice is to build immutable virtual  machine (VM) images to achieve predictable rollouts and rollbacks. But the main challenges include that VMs are heavyweight and non-portable.

The new way is to deploy containers, which implement OS-level virtualization rather than hardware virtualization. These containers are fully isolated from each other and also from the underlying host. The unique differentiations are that containers come with their own filesystems and can’t see other containers’ processes. It is possible to bound the computational resource usage of each container. Containers are easier and faster to build than VMs. As containers are totally decoupled from the underlying infrastructure and from the host machine’s filesystem, they are extremely portable across local and remote servers. Also multiple OS distributions do not be a barrier for the container portability.

Containers are extremely lightweight. One application/process/service can be packed and hosted inside each container. This one-to-one application-to-container relationship brings up a bevy of benefits (business, technical and user). That is, immutable container images can be created at build/release time itself rather than at deployment time. This enables to generate different images for the different versions/editions of the same application. Bringing in technical and business changes into application logic can be easily accomplished and accelerated. Each application need not be composed with the rest of the application stack. Also application is not tied up with underlying infrastructure. Therefore, containers can run anywhere (development, testing, staging and production servers). Containers are transparent and hence their monitoring, measurement and management are easier to do. The key container benefits of containers are given below

•	Agile application creation and running – Building container images through the techniques and tools provided by the opensource Docker platform for containerization-enablement is faster. Not only development but also packaging, shipping and running containers are transparent, quicker and simpler. 

•	Continuous integration, delivery and deployment – The containerization concept has been hugely contributing for automating the DevOps tasks (continuous integration, delivery and deployment). 

•	Separation of concerns between development and deployment – As indicated above, it is possible to create container images at the build/release time itself. The deployment is totally decoupled from the development and hence applications can run on any system infrastructure without any hitch or hurdle. That is, containerization fulfils the longstanding goal of software portability. 

•	Observability – With the containerization paradigm, not only OS-level information and metrics, but also application-level information such as the performance/throughput, health condition, and other value-adding and decision-enabling details  can be collected, cleansed and crunched to extricate actionable and timely insights. 

•	An Optimal Runtime for Microservices – Both cloud-native as well as enabled applications are predominantly microservices-centric. Containers are being positioned as the most optimal runtime for microservices. The convergence of containers and microservices is to bring a variety of benefits for cloud IT environments.   

•	Resource isolation – Due to the isolation brought in through containerization, application performance can be easily predicted.

•	Resource utilization – Due to the lightweight nature of containers, accommodating many containers in a single machine is possible. Thus containerization leads to heavily densed environments. Further on, the resource utilization goes up significantly.  

Containerization, without an iota of doubt, is being prescribed as the strategically sound tool for resolving most of the ills plaguing cloud environments. We have discussed the containerization phenomenon and the faster proliferation of microservices as the highly optimized application building-block and the deployment unit. Now there is a greater interest in converging these two strategically sound concepts. The combination is going to be disruptive, innovative and transformative for business enterprises. The enterprise and cloud IT divisions are going to be the most constructive and contributive as the promising convergence of microservices and containerization is to open up hitherto unknown and unheard possibilities and fresh opportunities for business and IT domains.

The Emergence of Containerized Cloud Environments


The Technical Challenges of Containerized Cloud Environments

 


Decoding the growing Role of Kubernetes for the Container Era

Kubernetes is a portable and extensible opensource platform for managing containerized workloads. Kubernetes automates the end-to-end container lifecycle management activities.  Configuration requirements are aptly declared and a host of automation modules of the Kubernetes platform are working together in realizing the desired state. Having understood the strategic importance of Kubernetes-like cluster and orchestration platforms in effectively and efficiently running containers in cloud environments, the tool ecosystem grows fast. Containers, being the favourite runtime to host and execute microservices, are turning out to be the most tuned resource for the cloud era. For automating the container creation, running, dismantling, stopping, replacing, replicating, etc., the contributions of container cluster and orchestration platform are growing great. 

Kubernetes (k8s) eliminates many of the manual activities for deploying and scaling containerized applications. Multi-container composite applications, which are business-centric, process-aware, mission-critical, flexible, event-driven, cloud-hosted, and service-oriented, are the new way of producing enterprise-scale applications. K8s plays a very vital role in producing such kinds of versatile, resilient, adaptive, adept and dynamic applications. K8s is penetrating into every kind of cloud environments (private, public, hybrid, and edge).

As indicated above, futuristic applications are being derived out of multiple containers fusing together. That is, containers have to be clustered and orchestrated in order to construct and deploy next-generation workloads in containerized cloud environments. Kubernetes orchestration enables building application services that span across multiple containers, schedules those containers across a cluster of nodes/hosts, scales those containers if necessary, and manages the health of those containers over time. The other important contributions of the K8s includes performing a seamless and spontaneous integration with networking, storage, telemetry and other core services in order to give a comprehensive yet compact container infrastructures for workloads. The idea is to bring as much automation possible to empower applications and services to deliver their functions as per the service level agreements (SLAs) agreed between providers and users. 
 
Having realized the strategic contributions of containers for the flourishing cloud era, the container embarkation journey started with all the clarity and confidence. The lightweight nature along with high transparency make containers more conducive for cloud applications and infrastructures. The fallout is that the number of containers in a cloud center goes up significantly. Therefore, the operational and management complexities of containerized clouds are steadily increasing. The way forward is to bring in deeper and decisive automation through automated tools and platforms. For the sake of simplicity, Kubernetes enables multiple containers to be clubbed together as a PoD. In a host/node/machine, there can be a few PoDs and each PoD comprises one or more containers. Docker networking capabilities can link multiple containers together. Kubernetes follow different mechanisms for container networking. Further on, Kubernetes schedule workloads onto container clusters. The load balancing feature of the Kubernetes platform can balance the dynamic loads across pods to ensure that the right number of containers are running all the time to facilitate the workloads to deliver without any hitch and hurdle. 

Containers are efficient in the sense that more works can be performed with less resources. The expensive IT resources are being maximally utilized to guarantee the required affordability. Software deployments and upgrades are being taken care of. Kubernetes mounts and adds storage to run stateful applications. It scales containers and the containers instances to enhance the availability of containerized applications. All the deployed software applications and their runtimes (containers) are being continuously monitored and managed. Various operational conditions including the application health condition are captured in order to do various appropriate activities such as auto-scaling, replication, etc. There are a number of open source tools emerging and evolving in order to make the leverage of Kubernetes easy to use. There are several project initiatives and implementations for service and container image registries, networking, security, etc. Kubernetes has become an automation, acceleration and augmentation platform for containerized environments












Conclusion

The digitization technologies and tools are becoming pervasive and persuasive. Nations across the globe are competing with one another in observing and absorbing the digitization processes, platforms, patterns, products, practices, and procedures in order to be smartly sensitive and really responsive to their constituents. All kinds of business establishments and corporates are eagerly strategizing to be elegantly digitized in their operations, offerings, and outputs. Human societies are being made aware of the significant impacts of digitization technologies. IT organizations are equally keen on bringing forth an arsenal of digitization-enablement solutions and services. Academic institutions, innovators and individuals are overwhelmingly convinced about the tactic as well as strategic implications of digitization. The awareness and articulation of digitization movement is definitely on the climb with the enhanced understanding of the business, technical and user benefits of digitization technologies such as cloud computing, data analytics (big, real-time, streaming, and IoT), enterprise mobility, web 2.0 (social web) and web 3.0 (semantic web), artificial intelligence (AI), microservices architecture, etc.  

Not only our computers, but also our everyday devices, handhelds, wearables, healthcare instruments, flying drones, industrial robots, consumer electronics, defence equipment, manufacturing machines, household wares and utensils, personal mobiles, and implantables such as sensors, actuators, etc. are also being systematically connected with one another and also with remotely held software applications, services and databases. There are a bevy of connectors, drivers, adapters, and other middleware solutions to enable the smart linkage amongst digitized artefacts, connected devices, and cloud-based applications. There is a close tie-up with the physical and the cyber worlds. This deeper and decisive connectivity results in highly integrated and insightful systems, networks, applications, and environments. All the anticipated and unanticipated interactions among all the participants and constituents generate a massive amount of multi-structured data. That is, the varying data speed, structure, schema, scope, and size lay a stimulating foundation for better, bigger and brighter possibilities and opportunities.  This chapter details the various characteristics, challenges and competencies of multi-cloud environments for the ensuing digital era. How hybrid clouds emerge as the most appropriate IT infrastructure for the digital economy and what are the promising technologies and tools in simplifying the realization of hybrid clouds. 


